# Scraping

Actual: 4 hours
ETA: 4 hours
Reviewed: No
Section: +extra, Section 18
Summary: No
complete: follow-up

# Web Scraping

### What is web scraping?

Web scraping is a technique that allows you to extract information from web pages automatically.  You can use web scraping to collect data for various purposes, such as analysis, research, marketing, etc. 
Web scraping usually involves saving the data in a local file or a database.  
Python is a popular language for web scraping because it has many libraries and tools that make it easy to work with web data.

---

- Generally involves:  downloading webpage, grabbing the data and then cleaning up the data.
- Essentially just dealing with JavaScript, CSS & HTML files

What is Web Scraping and How to Use It? - GeeksforGeeks. [https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/](https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/) Accessed 2023/03/01

---

### Why would we web scrape

- Data analytics and data science: Web scraping can provide data for machine learning algorithms, sentiment analysis, trend forecasting, etc.
- Marketing and sales: Web scraping can help with price optimization, competitor analysis, lead generation, customer feedback, etc.
- Public relations: Web scraping can help with media monitoring, reputation management, crisis response, etc.
- E-commerce: Web scraping can help with product cataloging, inventory management, product reviews, etc.
- [Recruitment](https://web.archive.org/web/20190824222347/http://www.entropywebscraping.com/2017/03/02/web-scraping-service-recruiting-agency/)
- [Sales Leads](https://web.archive.org/web/20190824222347/http://www.entropywebscraping.com/2017/01/02/sales-leads-data-web-scraping/)
- Marketing
- Real Estate
- Automotive
- Banking
- Finance
- Search Engine Optimization
- Social Media
- E-commerce

[Big List of Web Scraping Uses: Application of Web Scraping to Business | Entropy Web Scraping (archive.org)](https://web.archive.org/web/20190824222347/http://www.entropywebscraping.com/2017/01/01/big-list-web-scraping-uses/)

[The best websites to learn about APIs (bbvaapimarket.com)](https://www.bbvaapimarket.com/en/api-world/best-websites-learn-about-apis/)

---

### `/tobots.txt`

**what is robots txt**

A way of websites telling you what you can and cannot scrape (ethically)

there are ethical ways and and non-ethical ways

they cant really stop us but ethically we cannot use this data for commercial use.

```
URL:  https://news.ycombinator.com/robots.txt

User-Agent: *
Disallow: /x?
Disallow: /r?
Disallow: /vote?
Disallow: /reply?
Disallow: /submitted?
Disallow: /submitlink?
Disallow: /threads?
Crawl-delay: 30
```

there are some already built chrome-plugins web scrapers we can make use of (or anyone can make use of)

# API’s

- what are API’s
    
    An API is a way for two or more computer programs to communicate with each other¹. It is a type of software interface that defines how to use a service or a resource provided by another program³. For example, an API can allow you to access data from a website, send messages to a chatbot, or control a device remotely. An API specification is a document that describes how to build or use an API¹.
    
    Source: 
    Wikipedia. [https://en.wikipedia.org/wiki/API](https://en.wikipedia.org/wiki/API) Accessed 2023/03/02.
    Application Programming Interfaces Explained - AWS. [https://aws.amazon.com/what-is/api/](https://aws.amazon.com/what-is/api/) 
    
- what does API stand for?
    
    Application Interface *access*
    
- Some websites will have their own API’s that allow us to access the data
    
    sometimes 
    
    - have to pay for use
    - restricted to certain users/registering
    - restricted to certain amounts of data
    
    for example:
    
    [YouTube Data API  |  Google Developers](https://developers.google.com/youtube/v3)
    
- There are some API’s that allow us to access other websites information
    
    for example:
    
    [SWAPI - The Star Wars API](https://swapi.dev/)
    

# Googlebot

- what is Googlebot
    
    Googlebot is the name of the web crawler software used by Google that collects documents from the web to build a searchable index for the Google Search engine.
    
    It is also a generic name for Google’s two types of web crawlers: 
    
    - a desktop crawler that simulates a user on desktop, and a
    - mobile crawler that simulates a user on mobile
    
    Googlebot’s main function is to find content, evaluate it, classify it and index it in the search results pages
    
- what is Bing-bot
    
    Bing-bot is a web-crawling robot (type of internet bot), deployed by Microsoft October 2010 to supply Bing. 
    
    It collects documents from the web to build a searchable index for the Bing (search engine)
    
    It performs the same function as Google’s Googlebot1. When crawling websites, Bingbot looks at robots.txt for special instructions from website owners.
    

# Creating our first web-scraper

Modules we are going to use:

- `Beautiful Soup`
    
    *pip install beautifulsoup4*
    
    *from bs4 import BeautifulSoup*
    
    **Documentation:**
    
    [Beautiful Soup Documentation — Beautiful Soup 4.4.0 documentation](https://beautiful-soup-4.readthedocs.io/en/latest/)
    
    [Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
    
    ---
    
    **Why do we need?**
    
    Allows us to use the HTML and grab different Data - use the data we have gathered 
    
    Clean up the data we have downloaded
    
    ---
    
- `requests`
    
    *pip install requests*
    
    **Documentation:**
    
    [requests](https://pypi.org/project/requests/)
    
    ---
    
    **Why do we need?**
    
    Allows us to do the initial download of the HTML
    
    ---
    

---

### Requesting Data:

- We received all the HTML in a string format
- We can use Beautiful Soup to parse the data - meaning we can make it an object we can manipulate
- *“parse” definition*
    
    parsing is defined as the processing of a piece of python program and converting these codes into machine language. In general, we can say parse is a command for dividing the given program code into a small piece of code for analysing the correct syntax. Parsing helps to check if the code follows the rules and structure of Python language. There are different modules and tools that can help with parsing in Python
    

```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://news.ycombinator.com/')
print(res)        > <Response [200]>
print(res.text)   > We get all the HTML

```

**Inspecting the web page:**

> Inspect 
> (make bigger or you cant see) 
> Network 
> Refresh the page

we can see the html and we are getting response 200! ✅

![Untitled](Scraping%20784184afe0794731bf51da236f8eb93f/Untitled.png)

### Beautiful Soup Basics  & Selectors:

- Beautiful Soup has different parser’s (HTML, XML etc.)

```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://news.ycombinator.com/')
soup = BeautifulSoup(res.text, 'html.parser')   #turns it into an object
> We get all the HTML in HTML format

```

We can look things up in the inspector view and see what it is we want to find.
*for example:*

![Untitled](Scraping%20784184afe0794731bf51da236f8eb93f/Untitled%201.png)

```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://news.ycombinator.com/')
soup = BeautifulSoup(res.text, 'html.parser')

# print (soup.body)               #see just the body
# print (soup.body.contents)      #see the content in a list form
# print (soup.find_all('div'))    #all te div objects in a list form
# print (soup.find_all('a'))      #all the links that are on the page
# print (soup.title)              #give us the title of the page
# print (soup.a)                  #find the first link - link
# print (soup.find('a'))          #find the first item - link

print(soup.find(id="score_34973016"))
>
<span class="score" id="score_34973016">10 points</span>
```

- One of the best ways to use soup object is to use the `select` method
    - `select` allows us to grab a piece of data from the data we just downloaded - using a CSS selector (not covered in this course)
    - Here is more info on CSS selectors:  [https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Selectors](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Selectors)
        
        ```python
        import requests
        from bs4 import BeautifulSoup
        
        res = requests.get('https://news.ycombinator.com/')
        soup = BeautifulSoup(res.text, 'html.parser')
        
        print (soup.select('.score'))           #the '.' means what comes next is a class - this will output all the scores on the page
        print (soup.select('#score_34982181'))   #this will give us the individual thing
        
        >
        [<span class="score" id="score_34991053">385 points</span>, <span class="score" id="score_34992891">58 points</span>, <span class="score" id="score_34993589">18 points</span>, <span class="score" id="score_34986264">116 points</span>, <span class="score" id="score_34982157">92 points</span>, <span class="score" id="score_34989407">216 points</span>, <span class="score" id="score_34992615">30 points</span>, <span class="score" id="score_34988748">238 points</span>, <span class="score" id="score_34990666">122 points</span>, <span class="score" id="score_34977233">45 points</span>, <span class="score" id="score_34992215">32 points</span>, <span class="score" id="score_34990844">124 points</span>, <span class="score" id="score_34987658">183 points</span>, <span class="score" id="score_34971765">178 points</span>, <span class="score" id="score_34979104">21 points</span>, <span class="score" id="score_34985848">1145 points</span>, <span class="score" id="score_34974753">238 points</span>, <span class="score" id="score_34974791">6 points</span>, <span class="score" id="score_34990302">83 points</span>, <span class="score" id="score_34976444">70 points</span>, <span class="score" id="score_34981946">75 points</span>, <span class="score" id="score_34982181">14 points</span>, <span class="score" id="score_34973016">11 points</span>, <span class="score" id="score_34992219">19 points</span>, <span class="score" id="score_34991802">33 points</span>, <span class="score" id="score_34987834">101 points</span>, <span class="score" id="score_34989112">89 points</span>, <span class="score" id="score_34986691">175 points</span>, <span class="score" id="score_34990229">301 points</span>]
        >
        [<span class="score" id="score_34982181">14 points</span>]
        ```
        

---

### Hacker news project:  [Hacker News (ycombinator.com)](https://news.ycombinator.com/)

- Quick Note on next lecture - **.storylink to .titleline**
    
    Heads up! In the next video we will learn about selectors and we are going to use the Hackernews website to select some stories. Hackernews now uses the `.titleline` class instead of the `.storylink` class so you just need to make sure you enter `.titleline` in the next video when you see me use `.storylink`Finally, in the code attached I use `.titleline > a` because the link is now inside the first <a> tag under the titleline element.
    
    ![https://img-b.udemycdn.com/redactor/raw/article_lecture/2022-10-13_16-42-55-c92ab59cfc2edf850f3f365b5116041f.png](https://img-b.udemycdn.com/redactor/raw/article_lecture/2022-10-13_16-42-55-c92ab59cfc2edf850f3f365b5116041f.png)
    
    I've attached the updated project for you to this lesson in case you need it. I will link to it at the end of this section as well :)
    
    ---
    

---

### Lets scrape the website and create our own hacker news feed with only things above a certain amount of upvotes

- Now we want to try and sort this information - we want to grab only links that have over a certain amount of points.
    
    ```python
    import requests
    from bs4 import BeautifulSoup
    
    res = requests.get('https://news.ycombinator.com/')
    soup = BeautifulSoup(res.text, 'html.parser')
    
    links = (soup.select('titleline'))
    votes = (soup.select('.score'))          
    
    print(votes[0])
    print(votes[0].get('id')  #we can chain on from the votes object we created 
    
    >
    <span class="score" id="score_34991053">388 points</span>
    score_34991053
    ```
    
- Next step - combining the above to make it more useful
    - so here we have created a function to get some of the data we want to work with
        
        ```python
        import requests
        from bs4 import BeautifulSoup
        
        res = requests.get('https://news.ycombinator.com/')
        soup = BeautifulSoup(res.text, 'html.parser')
        
        links = (soup.select('.titleline > a'))
        votes = (soup.select('.score'))          
        
        def create_custom_hn(links, subtext):
            hn = []        
            #empty list we can append with the data we want                  
            for idx, item in enumerate(links):
                #if statement will come here later to fix the error - "IndexError: list index out of range"
                title = links[idx].getText()                           
                #above is getting the title in a text format
                href = links[idx].get('href', None)                    
                #above is getting the link (the attribute not the text) and if there is no link, the default is None
                points = int(votes[idx].getText().replace(' points', ''))       
                #above is getting the vots on the website and converting it to an int and removing the 'points'
                print(points)
                hn.append({'title' : title, 'link': href})
            return hn                
            
        print(create_custom_hn(links, votes))
        
        >
        140
        156
        130
        147
        244
        87
        3
        258
        44
        420
        58
        45
        134
        207
        195
        45
        40
        12
        192
        258
        1173
        95
        31
        79
        22
        72
        6
        37
        15
        Traceback (most recent call last):
          File "c:\Users\Nitropc\Documents\PythonScripts\web_scraping\scraper.py", line 22, in <module>
            print(create_custom_hn(links, votes))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
          File "c:\Users\Nitropc\Documents\PythonScripts\web_scraping\scraper.py", line 16, in create_custom_hn
            points = int(votes[idx].getText().replace(' points', ''))
                         ~~~~~^^^^^
        IndexError: list index out of range
        ```
        
- Fixing the problem
    
    What is the problem? 
    
    The “IndexError:  list index out of range”
    
    Why is this problem happening?
    
    The simple reason is that when we are calling the “points” we are getting an error as some of the news articles do not have any points/upvotes. 
    Therefore python gets confused here and says, I don’t know what to do - there are more “titles” & “links” than there are “points”
    
    What is the solution?
    
    We are going to change the way we get points.  Instead we are going to get something called the subtext - which we found every title has.
    Subtext is actually the little line under the Title that would include upvotes, authors name, time of post etc.  
    
    ```python
    import requests
    from bs4 import BeautifulSoup
    
    res = requests.get('https://news.ycombinator.com/')
    soup = BeautifulSoup(res.text, 'html.parser')
    
    links = (soup.select('.titleline > a'))
    subtext = soup.select('.subtext')
    
    def create_custom_hn(links, subtext):
        hn = []
        for idx, item in enumerate(links):
            #if statement
            title = item.getText()                  #changed from  links[idx] to item - because we can and easier to read               
            href = item.get('href', None)           #changed from  links[idx] to item - because we can and easier to rea             
            votes = subtext[idx].select('.score')   #we cant change to item because the for loop does not call subtext from the function  
    				#above is getting the vote count
            if len(votes):         #this if statement only takes titles with more than 1 upvote or else it ignores the title
                points = int(votes[0].getText().replace(' points', ''))       
    						#above is getting the vots on the website and converting it to an int and removing the 'points'
                print(points)
                hn.append({'title' : title, 'link': href, 'votes': points})
        return hn                
        
    
    print(create_custom_hn(links, subtext))
    
    >
    [{'title': 'Royal Astronomical Society: all journals to publish as open access from 2024', 'link': 'https://ras.ac.uk/news-and-press/news/royal-astronomical-society-announces-all-journals-publish-open-access-2024', 'votes': 188}, {'title': 'Building a Better World Without Jobs – 20M Video', 'link': 'https://workforcefuturist.substack.com/p/building-a-better-world-without-jobs-video', 'votes': 14}, {'title': 'Ask HN: How to get an accessibility tester job as a blind programmer?', 'link': 'item?id=34986264', 'votes': 175}, {'title': 'Europe pushing for lunar time zone', 'link': 'https://apnews.com/article/moon-time-zone-space-2b0124415c14755e08a58e1b5ed5362a', 'votes': 138}, {'title': "Don't let Event-Driven Architecture buzzwords fool you", 'link': 'https://event-driven.io/en/dont_let_event_driven_architecture_buzzwords_fool_you/', 'votes': 19}, {'title': 'Asteroid lost 1M kilograms after collision with DART spacecraft', 'link': 'https://www.nature.com/articles/d41586-023-00601-4', 'votes': 158}, {'title': 'Creating Isometric RPG Game Backgrounds', 'link': 'https://talesofsyn.com/posts/creating-isometric-rpg-game-backgrounds', 'votes': 254}, {'title': 'ChatML: ChatGPT API expects a structured format, called Chat Markup Language', 'link': 'https://github.com/openai/openai-python/blob/main/chatml.md', 'votes': 268}, {'title': 'FreeBSD Home Audio Studio', 'link': 'https://vermaden.wordpress.com/2023/03/02/freebsd-home-audio-studio/', 'votes': 51}, {'title': 'U.S. Postal Service starts nationwide electric vehicle fleet, buying 9,250 EVs', 'link': 'https://www.cbsnews.com/news/u-s-postal-service-starts-nationwide-electric-vehicle-fleet-buying-9250-evs-and-thousands-of-charging-stations/', 'votes': 434}, {'title': 'Researchers have discovered a new type of coexistence between algae and fungi', 'link': 'https://phys.org/news/2023-02-coexistence-algae-fungi.html', 'votes': 61}, {'title': 'Effortless Performance Improvements in C++: std:unordered_map', 'link': 'https://julien.jorge.st/posts/en/effortless-performance-improvements-in-cpp-std-unordered_map/', 'votes': 48}, {'title': '5k-Year-Old Tavern with Food Still Inside Discovered in Iraq', 'link': 'https://www.smithsonianmag.com/smart-news/5000-year-old-tavern-discovered-in-iraq-180981564/', 'votes': 51}, {'title': 'Aboriginal Australian genomes reveal Indian ancestry (2013)', 'link': 'https://www.nature.com/articles/nature.2013.12219', 'votes': 197}, {'title': 'Oldest water on earth, in a Canadian mine (2021)', 'link': 'https://www.macleans.ca/society/science/this-geologist-found-the-oldest-water-on-earth-in-a-canadian-mine/', 'votes': 49}, {'title': 'US-Japan team hails H2-boron plasma fusion breakthrough', 'link': 'https://www.rechargenews.com/energy-transition/100-000-years-of-power-us-japan-team-hails-h2-boron-plasma-fusion-breakthrough/2-1-1411318?zephr_sso_ott=QAIu08', 'votes': 136}, {'title': 'Early-life stress can disrupt maturation of brain’s reward circuits', 'link': 'https://news.uci.edu/2023/02/27/early-life-stress-can-disrupt-maturation-of-brains-reward-circuits-promoting-disorders/', 'votes': 272}, {'title': 'Writing an OS in Rust to run on RISC-V', 'link': 'https://gist.github.com/cb372/5f6bf16ca0682541260ae52fc11ea3bb', 'votes': 198}, {'title': 'Swarm M138 Modem', 'link': 'https://swarm.space/product/swarm-m138-modem/', 'votes': 4}, {'title': 'Shelf life: Judging books by their covers', 'link': 'https://www.the-tls.co.uk/articles/shelf-life-afterthoughts-irina-dumitrescu/', 'votes': 14}, {'title': 'Introducing ChatGPT and Whisper APIs', 'link': 'https://openai.com/blog/introducing-chatgpt-and-whisper-apis', 'votes': 1184}, {'title': 'ARM vs. Intel on Amazon’s Cloud: A URL Parsing Benchmark', 'link': 'https://lemire.me/blog/2023/03/01/arm-vs-intel-on-amazons-cloud/', 'votes': 99}, {'title': 'Startup Decoupling and Reckoning', 'link': 'https://blog.eladgil.com/p/startup-decoupling-and-reckoning', 'votes': 33}, {'title': 'Launch HN: EdgeBit (YC W23) – live software vulnerability analysis', 'link': 'item?id=34981946', 'votes': 79}, {'title': 'Oxide and Friends – Rack-scale Networking [audio]', 'link': 'https://www.youtube.com/watch?v=AkWh2Sms3aw', 'votes': 74}, {'title': 'Cromemco Z-2D', 'link': 'https://computeradsfromthepast.substack.com/p/cromemco-z-2d', 'votes': 25}, {'title': 'The Surprisingly Scientific Roots of Monkey Bars', 'link': 'https://www.smithsonianmag.com/history/history-monkey-bars-180981556/', 'votes': 18}, {'title': 'Show HN: ChatGPT-powered dystopia simulator', 'link': 'https://future.attejuvonen.fi/', 'votes': 121}, {'title': 'Birds and Frogs (2008) [pdf]', 'link': 'https://www.ams.org/notices/200902/rtx090200212p.pdf', 'votes': 6}]
    PS C:\Users\Nitropc\Documents\PythonScripts>
    ```
    
- Cleaning up the terminal output
    
    The output from this web scraper is working but it looks a bit messy - so we need to clean things up a bit here. 
    
    We are going to use a built-in module called, “Pretty Print”
    
    ```python
    import requests
    from bs4 import BeautifulSoup
    import pprint                   #outputs things in an easy to read format
    
    res = requests.get('https://news.ycombinator.com/')
    soup = BeautifulSoup(res.text, 'html.parser')
    
    links = (soup.select('.titleline > a'))
    subtext = soup.select('.subtext')
    
    def create_custom_hn(links, subtext):
        hn = []
        for idx, item in enumerate(links):
            title = item.getText()                  
            href = item.get('href', None)           
            votes = subtext[idx].select('.score')   
            if len(votes):                                                 
                points = int(votes[0].getText().replace(' points', ''))      
                hn.append({'title' : title, 'link': href, 'votes': points})
        return hn                
        
    
    pprint.pprint(create_custom_hn(links, subtext))  #note the pprint.pprint here
    
    >
    [{'link': 'https://ras.ac.uk/news-and-press/news/royal-astronomical-society-announces-all-journals-publish-open-access-2024',
      'title': 'Royal Astronomical Society: all journals to publish as open access '
               'from 2024',
      'votes': 188},
     {'link': 'https://workforcefuturist.substack.com/p/building-a-better-world-without-jobs-video',
      'title': 'Building a Better World Without Jobs – 20M Video',
      'votes': 14},
     {'link': 'item?id=34986264',
      'title': 'Ask HN: How to get an accessibility tester job as a blind '
               'programmer?',
      'votes': 175},
     {'link': 'https://apnews.com/article/moon-time-zone-space-2b0124415c14755e08a58e1b5ed5362a',
      'title': 'Europe pushing for lunar time zone',
      'votes': 138},
     {'link': 'https://event-driven.io/en/dont_let_event_driven_architecture_buzzwords_fool_you/',
      'title': "Don't let Event-Driven Architecture buzzwords fool you",
      'votes': 19},
     {'link': 'https://www.nature.com/articles/d41586-023-00601-4',
      'title': 'Asteroid lost 1M kilograms after collision with DART spacecraft',
      'votes': 158},
     {'link': 'https://talesofsyn.com/posts/creating-isometric-rpg-game-backgrounds',
      'title': 'Creating Isometric RPG Game Backgrounds',
      'votes': 254},
     {'link': 'https://github.com/openai/openai-python/blob/main/chatml.md',
      'title': 'ChatML: ChatGPT API expects a structured format, called Chat '
               'Markup Language',
      'votes': 268},
     {'link': 'https://vermaden.wordpress.com/2023/03/02/freebsd-home-audio-studio/',
      'title': 'FreeBSD Home Audio Studio',
      'votes': 51},
     {'link': 'https://www.cbsnews.com/news/u-s-postal-service-starts-nationwide-electric-vehicle-fleet-buying-9250-evs-and-thousands-of-charging-stations/',
      'title': 'U.S. Postal Service starts nationwide electric vehicle fleet, '
               'buying 9,250 EVs',
      'votes': 434},
     {'link': 'https://phys.org/news/2023-02-coexistence-algae-fungi.html',
      'title': 'Researchers have discovered a new type of coexistence between '
               'algae and fungi',
      'votes': 61},
     {'link': 'https://julien.jorge.st/posts/en/effortless-performance-improvements-in-cpp-std-unordered_map/',
      'title': 'Effortless Performance Improvements in C++: std:unordered_map',
      'votes': 48},
     {'link': 'https://www.smithsonianmag.com/smart-news/5000-year-old-tavern-discovered-in-iraq-180981564/',
      'title': '5k-Year-Old Tavern with Food Still Inside Discovered in Iraq',
      'votes': 51},
     {'link': 'https://www.nature.com/articles/nature.2013.12219',
      'title': 'Aboriginal Australian genomes reveal Indian ancestry (2013)',
      'votes': 197},
     {'link': 'https://www.macleans.ca/society/science/this-geologist-found-the-oldest-water-on-earth-in-a-canadian-mine/',
      'title': 'Oldest water on earth, in a Canadian mine (2021)',
      'votes': 49},
     {'link': 'https://www.rechargenews.com/energy-transition/100-000-years-of-power-us-japan-team-hails-h2-boron-plasma-fusion-breakthrough/2-1-1411318?zephr_sso_ott=QAIu08',
      'title': 'US-Japan team hails H2-boron plasma fusion breakthrough',
      'votes': 136},
     {'link': 'https://news.uci.edu/2023/02/27/early-life-stress-can-disrupt-maturation-of-brains-reward-circuits-promoting-disorders/',
      'title': 'Early-life stress can disrupt maturation of brain’s reward '
               'circuits',
      'votes': 272},
     {'link': 'https://gist.github.com/cb372/5f6bf16ca0682541260ae52fc11ea3bb',
      'title': 'Writing an OS in Rust to run on RISC-V',
      'votes': 198},
     {'link': 'https://swarm.space/product/swarm-m138-modem/',
      'title': 'Swarm M138 Modem',
    PS C:\Users\Nitropc\Documents\PythonScripts> & C:/Users/Nitropc/AppData/Local/Programs/Python/Python311/python.exe c:/Users/Nitropc/Documents/PythonScripts/web_scraping/scraper.py
    [{'link': 'https://ras.ac.uk/news-and-press/news/royal-astronomical-society-announces-all-journals-publish-open-access-2024',
      'title': 'Royal Astronomical Society: all journals to publish as open access '
               'from 2024',
      'votes': 189},
     {'link': 'https://workforcefuturist.substack.com/p/building-a-better-world-without-jobs-video',
      'title': 'Building a Better World Without Jobs – 20M Video',
      'votes': 15},
     {'link': 'item?id=34986264',
      'title': 'Ask HN: How to get an accessibility tester job as a blind '
               'programmer?',
      'votes': 175},
     {'link': 'https://apnews.com/article/moon-time-zone-space-2b0124415c14755e08a58e1b5ed5362a',
      'title': 'Europe pushing for lunar time zone',
      'votes': 139},
     {'link': 'https://event-driven.io/en/dont_let_event_driven_architecture_buzzwords_fool_you/',
      'title': "Don't let Event-Driven Architecture buzzwords fool you",
      'votes': 21},
     {'link': 'https://www.nature.com/articles/d41586-023-00601-4',
      'title': 'Asteroid lost 1M kilograms after collision with DART spacecraft',
      'votes': 158},
     {'link': 'https://talesofsyn.com/posts/creating-isometric-rpg-game-backgrounds',
      'title': 'Creating Isometric RPG Game Backgrounds',
      'votes': 256},
     {'link': 'https://github.com/openai/openai-python/blob/main/chatml.md',
      'title': 'ChatML: ChatGPT API expects a structured format, called Chat '
               'Markup Language',
      'votes': 269},
     {'link': 'https://vermaden.wordpress.com/2023/03/02/freebsd-home-audio-studio/',
      'title': 'FreeBSD Home Audio Studio',
      'votes': 51},
     {'link': 'https://www.cbsnews.com/news/u-s-postal-service-starts-nationwide-electric-vehicle-fleet-buying-9250-evs-and-thousands-of-charging-stations/',
      'title': 'U.S. Postal Service starts nationwide electric vehicle fleet, '
               'buying 9,250 EVs',
      'votes': 436},
     {'link': 'https://phys.org/news/2023-02-coexistence-algae-fungi.html',
      'title': 'Researchers have discovered a new type of coexistence between '
               'algae and fungi',
      'votes': 61},
     {'link': 'https://julien.jorge.st/posts/en/effortless-performance-improvements-in-cpp-std-unordered_map/',
      'title': 'Effortless Performance Improvements in C++: std:unordered_map',
      'votes': 48},
     {'link': 'https://www.smithsonianmag.com/smart-news/5000-year-old-tavern-discovered-in-iraq-180981564/',
      'title': '5k-Year-Old Tavern with Food Still Inside Discovered in Iraq',
      'votes': 51},
     {'link': 'https://www.nature.com/articles/nature.2013.12219',
      'title': 'Aboriginal Australian genomes reveal Indian ancestry (2013)',
      'votes': 197},
     {'link': 'https://www.macleans.ca/society/science/this-geologist-found-the-oldest-water-on-earth-in-a-canadian-mine/',
      'title': 'Oldest water on earth, in a Canadian mine (2021)',
      'votes': 49},
     {'link': 'https://www.rechargenews.com/energy-transition/100-000-years-of-power-us-japan-team-hails-h2-boron-plasma-fusion-breakthrough/2-1-1411318?zephr_sso_ott=QAIu08',
      'title': 'US-Japan team hails H2-boron plasma fusion breakthrough',
      'votes': 138},
     {'link': 'https://gist.github.com/cb372/5f6bf16ca0682541260ae52fc11ea3bb',
      'title': 'Writing an OS in Rust to run on RISC-V',
      'votes': 198},
     {'link': 'https://swarm.space/product/swarm-m138-modem/',
      'title': 'Swarm M138 Modem',
      'votes': 4},
     {'link': 'https://openai.com/blog/introducing-chatgpt-and-whisper-apis',
      'title': 'Introducing ChatGPT and Whisper APIs',
      'votes': 1184},
     {'link': 'https://www.the-tls.co.uk/articles/shelf-life-afterthoughts-irina-dumitrescu/',
      'title': 'Shelf life: Judging books by their covers',
      'votes': 14},
     {'link': 'https://lemire.me/blog/2023/03/01/arm-vs-intel-on-amazons-cloud/',
      'title': 'ARM vs. Intel on Amazon’s Cloud: A URL Parsing Benchmark',
      'votes': 100},
     {'link': 'https://blog.eladgil.com/p/startup-decoupling-and-reckoning',
      'title': 'Startup Decoupling and Reckoning',
      'votes': 33},
     {'link': 'item?id=34981946',
      'title': 'Launch HN: EdgeBit (YC W23) – live software vulnerability analysis',
      'votes': 79},
     {'link': 'https://www.youtube.com/watch?v=AkWh2Sms3aw',
      'title': 'Oxide and Friends – Rack-scale Networking [audio]',
      'votes': 76},
     {'link': 'https://computeradsfromthepast.substack.com/p/cromemco-z-2d',
      'title': 'Cromemco Z-2D',
      'votes': 25},
     {'link': 'https://www.smithsonianmag.com/history/history-monkey-bars-180981556/',
      'title': 'The Surprisingly Scientific Roots of Monkey Bars',
      'votes': 18},
     {'link': 'https://future.attejuvonen.fi/',
      'title': 'Show HN: ChatGPT-powered dystopia simulator',
      'votes': 122},
     {'link': 'https://www.ams.org/notices/200902/rtx090200212p.pdf',
      'title': 'Birds and Frogs (2008) [pdf]',
      'votes': 6},
     {'link': 'https://news.greylock.com/unit-of-value-a-framework-for-scaling-42c092fba887?gi=4fabd48bb67e',
      'title': 'Unit of Value: A Framework for Scaling (2016)',
      'votes': 17}]
    ```
    
- Now we only want to print articles if they have over a 100 upvotes and then rank them in order of points/upvotes
    - We need to create a sorting function
    - Don’t forget to call on the function when its been made
    
    ```python
    import requests
    from bs4 import BeautifulSoup
    import pprint 
    
    res = requests.get('https://news.ycombinator.com/')
    soup = BeautifulSoup(res.text, 'html.parser')
    
    links = (soup.select('.titleline > a'))
    subtext = soup.select('.subtext')
    
    def sort_stories_by_votes(hnlist):                                  #This is a common sorting algortithm 
        return sorted(hnlist, key= lambda k:k['votes'], reverse=True)   
    		#The lambda is a bit confusing and encouraged to investigate more on our own time
    
    def create_custom_hn(links, subtext):
        hn = []
        for idx, item in enumerate(links):
            title = item.getText()                  
            href = item.get('href', None)          
            votes = subtext[idx].select('.score')   
            if len(votes):                                                    
                points = int(votes[0].getText().replace(' points', '')) 
                if points > 99:
                    hn.append({'title' : title, 'link': href, 'votes': points})
        return sort_stories_by_votes(hn)                                #remember to change this to first call on the sorting function
        
    
    pprint.pprint(create_custom_hn(links, subtext))
    
    >
    [{'link': 'https://openai.com/blog/introducing-chatgpt-and-whisper-apis',
      'title': 'Introducing ChatGPT and Whisper APIs',
      'votes': 1188},
     {'link': 'https://www.cbsnews.com/news/u-s-postal-service-starts-nationwide-electric-vehicle-fleet-buying-9250-evs-and-thousands-of-charging-stations/',
      'title': 'U.S. Postal Service starts nationwide electric vehicle fleet, '
               'buying 9,250 EVs',
      'votes': 439},
     {'link': 'https://github.com/openai/openai-python/blob/main/chatml.md',
      'title': 'ChatML: ChatGPT API expects a structured format, called Chat '
               'Markup Language',
      'votes': 274},
     {'link': 'https://talesofsyn.com/posts/creating-isometric-rpg-game-backgrounds',
      'title': 'Creating Isometric RPG Game Backgrounds',
      'votes': 261},
     {'link': 'https://gist.github.com/cb372/5f6bf16ca0682541260ae52fc11ea3bb',
      'title': 'Writing an OS in Rust to run on RISC-V',
      'votes': 201},
     {'link': 'https://ras.ac.uk/news-and-press/news/royal-astronomical-society-announces-all-journals-publish-open-access-2024',
      'title': 'Royal Astronomical Society: all journals to publish as open access '
               'from 2024',
      'votes': 197},
     {'link': 'https://www.nature.com/articles/nature.2013.12219',
      'title': 'Aboriginal Australian genomes reveal Indian ancestry (2013)',
      'votes': 197},
     {'link': 'item?id=34986264',
      'title': 'Ask HN: How to get an accessibility tester job as a blind '
               'programmer?',
      'votes': 180},
     {'link': 'https://www.nature.com/articles/d41586-023-00601-4',
      'title': 'Asteroid lost 1M kilograms after collision with DART spacecraft',
      'votes': 159},
     {'link': 'https://apnews.com/article/moon-time-zone-space-2b0124415c14755e08a58e1b5ed5362a',
      'title': 'Europe pushing for lunar time zone',
      'votes': 142},
     {'link': 'https://www.rechargenews.com/energy-transition/100-000-years-of-power-us-japan-team-hails-h2-boron-plasma-fusion-breakthrough/2-1-1411318?zephr_sso_ott=QAIu08',
      'title': 'US-Japan team hails H2-boron plasma fusion breakthrough',
      'votes': 139},
     {'link': 'https://future.attejuvonen.fi/',
      'title': 'Show HN: ChatGPT-powered dystopia simulator',
      'votes': 123},
     {'link': 'https://lemire.me/blog/2023/03/01/arm-vs-intel-on-amazons-cloud/',
      'title': 'ARM vs. Intel on Amazon’s Cloud: A URL Parsing Benchmark',
      'votes': 102}]
    ```
    
- Exercise
    
    We have been tasked to scrape not only the first page but also the second page of “Hacker News”
    
    - attempt & solution
        
        firstly there are a few ways I am thinking
        I am going to add the link to the second page as a second result 
        
        but I could like create an open ended link that sucks all the data from hackernews
        but I am scared I get ip Banned for doing this. 
        
        ```python
        import requests
        from bs4 import BeautifulSoup
        import pprint 
        
        res = requests.get('https://news.ycombinator.com/')
        res2 = requests.get('https://news.ycombinator.com/?p=2')
        soup = BeautifulSoup(res.text, 'html.parser')
        soup2 = BeautifulSoup(res.text, 'html.parser')
        
        links = (soup.select('.titleline > a'))
        subtext = soup.select('.subtext')
        links2 = (soup2.select('.titleline >a'))
        subtext2 = soup2.select('.subtext')
        
        all_links = links + links2
        all_subtext = subtext + subtext2
        
        def sort_stories_by_votes(hnlist):                                  #This is a common sorting algortithm 
            return sorted(hnlist, key= lambda k:k['votes'], reverse=True)   #The lambda is a bit confusing and encouraged to investigate more on our own time
        
        def create_custom_hn(links, subtext):
            hn = []
            for idx, item in enumerate(links):
                title = item.getText()                  
                href = item.get('href', None)          
                votes = subtext[idx].select('.score')   
                if len(votes):                                                    
                    points = int(votes[0].getText().replace(' points', '')) 
                    if points > 99:
                        hn.append({'title' : title, 'link': href, 'votes': points})
            return sort_stories_by_votes(hn)                                #remember to change this to first call on the sorting function
            
        
        pprint.pprint(create_custom_hn(all_links, all_subtext))
        ```
        
- What next?
    - What are some more things we can do?
        - display on own HTML (will learn in next session)
        - try with other websites
    - working with an API that is official like Airbnb
    - Using Scrapy - the framework
    - store in text file or CSV file
    - store in databases
        - MondoDB
        - MySQL
    - another idea:  (hacker news scraping job opportunities)